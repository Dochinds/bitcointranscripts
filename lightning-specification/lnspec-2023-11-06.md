---
title: Lightning Specification Meeting
transcript_by: carlaKC via TBTBTC v1.0.0
tags: ['lightning']
date: 2023-11-06
---

Speaker 0: 00:00:05

Perfect.

Speaker 1: 00:00:08

So I moved as a first item on the to-do list today, because we finally have interrupted between Sea Lightning and Eclair. We were only missing the reestablished part, and everything was mostly okay from the beginning. It looks like the specs seems to be clear enough because we both understood it the same way. So now we really have full interrupt on master and I guess this should go in a release with experimental flags for CLN. Is that correct? Okay.

Speaker 2: 00:00:36

Yeah.

Speaker 1: 00:00:38

Okay. So I think it's Lisa rebased the PR and squashed some commits to clean up the commit history a bit. So I guess this is the last call for dual funding before we merge that. So, hey, Lisa. And I don't know if people want to do for, if there is anything pending from teams who are in the middle of implementing that. Is there some feedback here?

Speaker 0: 00:01:04

We have very light progress. I would not say we have anything that's going to give you material feedback yet.

Speaker 1: 00:01:13

Okay.

Speaker 3: 00:01:14

Yeah. And then we're taking like the long way around with this in terms of like down code and stuff, which goes into dofunding and splicing eventually.

Speaker 1: 00:01:22

Okay. So do Dunsen or anyone who is reviewing that on the LND side as well, want to have a last look at the PR and make sure that we are not missing important things before we merge it.

Speaker 0: 00:01:38

I can tag Duncan and

Speaker 1: 00:01:40

see if he has any more feedback.

Speaker 4: 00:01:43

He's been in

Speaker 0: 00:01:44

and out, I think he's off this week. But I can ask him if he has some time.

Speaker 1: 00:01:51

Okay, I think helping on the PR as well for the previous reviewer, saying that he might merge that soon, so if people want to have a last look at it, now would be the time. So I guess that's it for dual funding. Simply for simplifying mutual close. Is there anything new since the last two weeks?

Speaker 2: 00:02:16

No, sorry.

Speaker 3: 00:02:17

Yeah, I think this is in like the need implementation phase basically, right?

Speaker 2: 00:02:21

Yeah.

Speaker 3: 00:02:23

And yeah.

Speaker 2: 00:02:24

I can't even remember if I added the end sequence set.

Speaker 3: 00:02:31

It doesn't change what the sequence is on the call question direction or?

Speaker 2: 00:02:36

Oh yeah, so basically you'll nominate what you want the end sequence to be as long as it's RBFable.

Speaker 3: 00:02:42

Oh sure, sure.

Speaker 2: 00:02:43

So you can, you know, there's a bit saying what values you can use for things and you know best practices etc.

Speaker 3: 00:02:58

Cool, someone wants to check out again as well. Again as well.

Speaker 1: 00:03:15

On the LND side, what's your plan to integrate that with Taproot?

Speaker 3: 00:03:20

The plan is to use our current staging feature bit as what we have currently. And then once we actually have the factual feature bit, to basically kind of assume this existence of this.

Speaker 2: 00:03:30

Because I'm assuming this is

Speaker 3: 00:03:31

going to get in well before that. So we'll just, I mean, we'll maybe even have like a dependency in our codebase at least as far as like, you know, once you have the final type root bit, you basically also should have this one, because that would be the co-op closed forward. So it should be a pretty clean transition. I think it's also like a good idea that we started to do the same thing in the first place. It simplifies the whole like, oh, I was on type root 0.95, you know, we merged 1.0 and blah, blah, blah. So I think we have that path clear at least.

Speaker 1: 00:03:58

Sound good. I guess next up is Pierced Orange. Rusty, you put that one on the list. For what it's worth, I think that mine and this one, even if they diverge, this should rather be a blip, I think, than a bolt. I think this is really an add-on that doesn't need to be in the bolt. But...

Speaker 2: 00:04:32

I don't mind. I mean, I would like to see it implemented everywhere. It's only interesting because it has asymmetric feature bits. It's one of the few, it's the first asymmetric feature bit we have. Like somebody has, I offer this feature and someone else is like, I need this feature. And they're separate bits. Although in our implementation we'll be offering both. I mean it's trivial. It really is trivial. Basically you just, you know, if they send you a new message you just stash it somewhere and when they reconnect you throw it back at them. Yeah we're hoping to get more sophisticated because people don't do backups. Hell, I don't do backups.

Speaker 3: 00:05:12

We should

Speaker 2: 00:05:12

all do backups people. So just spraying it at your peers gives you an increased chance that if you just managed to say if you're secret, your master secret in some form, at least this will let you get stuff back. So we're basically just using it for static backups at the moment, but we would hope to get a bit more sophisticated and that would be kind of cool. So it's kind of resting on the whole idea that we've discovered that generally your peers are kind of trustworthy. So best effort works shockingly well. So you really can't get much, can't get much simpler than this, right? You just, you know, throw an odd message in there and send it back. So we have we've implemented it. We do this at the moment. And it would be cool to see other people do it. What we haven't done is if you restore, so our plan is if you restore, you kind of look through the, you grab all the gossip and see if you've got any public channels, but it doesn't cover if you've got, and then you can connect to one of your unknown peers, right, from that. And then hopefully they'll throw you back your peer storage and you can kind of bootstrap off that if you've got private channels. If you only have private channels, it's harder. You can try to connect to everyone on the network and see if anyone gives you a backup. The other option, of course, is that there could be people who will do like, you know, you throw them some sats, and they will back up for you anyway, right? It's assumed at the moment, if the idea is that you will best effort store a blob if you have a channel with someone, but not necessarily if you don't. But you could totally, you know, go cool, I'll store your crap for a year for, I get 64K, right? It really is in the noise.

Speaker 0: 00:06:56

So that's the only possible extension to this really.

Speaker 2: 00:06:59

So yeah, it's trivial, we have an implementation of it. I don't know. So Aditya has got a grant and he's working on this. And I think he's talking about doing it for like trying to hack on LDK to add it there. But the only thing about that is that technical users have two independent implementations. And I'm like, if he implements both, are they still independent implementations? Left hand versus right hand? I don't know. So, But it is pretty straightforward.

Speaker 3: 00:07:34

Yeah. This seems super simple. I think we're going to take a look at doing this as well, because we have our SCB flow and I think we have a similar flow, which is a matter of doing the storage stuff and completion shouldn't be trivial. We have AED stuff on our end already. But yeah, I'll write this down to like, see what we can put this on future milestone.

Speaker 2: 00:07:52

Yeah, yeah, it just it just seems like a no brainer. Something that that that Ron should probably start doing. The question, the question is someone asked like, what happens if you've got more channels and fits in 64k? It's like, get a serious fucking backup solution. Like don't giant node or rely on having you know, like, I don't care. So it you know, it fits pretty well.

Speaker 3: 00:08:17

Make sense. Cool.

Speaker 2: 00:08:19

Yeah. Yeah. And we for we could just come up with a crappy back 32 styling coding CL emerge for the static backup file format, just so people can cut and paste it and feed it to our RPCs and stuff like that if they have one lying around. So yeah, it's basically a tag on front of this encrypted SCB blob. Cool. Okay. No, that's it. I just wanted to raise everyone's attention that it's being worked on.

Speaker 3: 00:08:51

Cool. Then you already have an implementation of the ship basically, right? It's a virtual like that?

Speaker 2: 00:08:55

Yeah. Cool. Yeah. You connect to it, you'll get your stuff back. The spec doesn't say you have to commit. I mean, you know, you basically in theory, you don't even need to put in a database, you just write to do somewhere and best effort. It's kind of hard to specify that you definitely have, you know, there's no, this is, you know, I mean, a coin. That's right. You know, you're just you're just, you know, you're, You're relying on the goodness of strangers. Don't ask too much.

Speaker 1: 00:09:23

Cool.

Speaker 3: 00:09:31

Spec cleanup. I think we're going to do the required feature bit thing for 18, which is our next major release. And at least then, you know, that's kind of like on our radar still to, get that in and we have an issue for it as well. I'm not sure if anyone has started. I think CLI can start to do some of the, some of these though.

Speaker 2: 00:09:46

We've done it for this release, which is in RC1. So, so far so good.

Speaker 3: 00:09:57

Does Claire already do this, Tino?

Speaker 1: 00:10:00

Yeah, he's on our network branch and it should be on our node in the next few days

Speaker 3: 00:10:07

Yeah, should we master I think I'm like Okay. Okay. Okay. Okay. Just pick me up offers. Okay. Does spec cleanup offers? I think the last time...

Speaker 1: 00:10:39

I think the last time we were just asking people whether they made progress on the SCID or pubkey encoding. And I think one that has it implemented right now, we have a PR that is ready to review, but yeah, I think we need other people to have it and also to include it in the test vectors, I guess.

Speaker 3: 00:10:59

But like that's optional to my knowledge, right? That's just like a more compact version basically. Or is that meant to be like the standard where you're going forward?

Speaker 0: 00:11:07

Meant to be the standard.

Speaker 4: 00:11:09

Well, I think it's optional in the way it can be used, right? You can be either or.

Speaker 0: 00:11:15

I guess it's optional for the recipient, but the sender needs to support it if recipients are going to generally use it.

Speaker 4: 00:11:21

Yeah, that's true. So I guess on our side, we did have Munity wallets integrate offers in this experimental way, not in a release or anything, but they were able to pay an offer generated by, I guess, with Sea Lightning for their LSP. And that was with a direct connection, which is what we support currently. And then they were also able to parameterize our implementation so they could do a muting immunity through an LSP along with the channels public. So we're kind of there, but there's still more robustness that needs to be supported on our end for our next release. MARTIN

Speaker 1: 00:12:13

SPLITT Are there interesting things that you learned during that experiment? ANDREW BROGDON

Speaker 4: 00:12:17

Yeah, the one thing is they couldn't use a, so by default, their channels are private with their LSDs, and we couldn't route to those, just the way our routing algorithm set up. And I think they could kind of hack it with like parameterizing their own router, but we didn't really go too far down that route. Otherwise, nothing surprising yet, but like I said, we require a direct connection for any messages. But it was nice seeing that working correctly.

Speaker 3: 00:12:44

Cool. So have people started to do more end-to-end routed stuff? I'm curious what people are presenting as far as the fallback. For example, a wallet, what timeout you're gonna use for actually fetching it. If it does timeout, did you just retry more? Are you trying parallel routes? Just thinking about the end wallet experience versus to get that as good or better to what we have today, basically.

Speaker 4: 00:13:09

Our current version doesn't do any retries, but we will take every path that's in the offer up to 10 paths, I think, or eight or 10, if you're rich, and just send invoice requests to all of them. And we'll make sure to pay one of them. If we are the person that receives those requests, we would issue more than one invoice, I believe.

Speaker 3: 00:13:36

Oh, I see what you're saying.

Speaker 4: 00:13:39

I guess you

Speaker 3: 00:13:41

ignore the rest of them once like the main one has been settled or something like that.

Speaker 4: 00:13:45

I mean, they would hopefully only pay one of them. Sure. They technically issued more than one request. But our code is set that we would only pay one of them. We basically put a payment ID in the metadata, and it's encrypted. And then we'll have some state tracking whether we've sent the payment yet or not.

Speaker 0: 00:14:08

And we fail after about three minutes if we haven't gotten an invoice in response to our invoice requests.

Speaker 3: 00:14:19

Yeah, that might be

Speaker 4: 00:14:20

should be down to one minute. I forget what we settled on but and then for refunds it's a little different. Refunds I mean like inverse request that is without an offer. It's just our phrasing them in our code And there it's based on the expiration of the refund.

Speaker 1: 00:14:38

We will also be starting to prototype this inside Phoenix to see what the rise is when you actually start using it in a mobile wallet. So this is on our roadmap for the next few months. We don't really have a timeline, but this is something we'll be working on soon.

Speaker 3: 00:14:54

Yeah, I'm definitely interested in like the wallet flows, you know, for example, we did like APIs as well. Cause like, you know, right now we just have like the simple, you know, add invoice, get invoice, but then like the whole offer thing, things like that. But also, I guess, yeah, for the wallets, at least on our end, people on top of it. But yeah, I mean, now that like, we're finding, you know, the inside of the paths, the stuff that we can start to be thinking about API wise.

Speaker 4: 00:15:15

Yeah, for the API, like I mentioned earlier, like we'll just basically use the same payment ID in each of the invoice requests that we sent out. And that's like, they're like the UX, the developer UX, they're sort of agnostics to the fact that there's more than one message flying around.

Speaker 3: 00:15:31

Gotcha. Yeah, because we're in the middle of like a database rework basically, just because it was just hacks on hacks. As maybe you guys know from the early days. And then so ideally we can like revamp this stuff to like have better support for attracting this on the database level, which would just make stuff easier. Because right now we have like, right now our notification API, you can't get the first invoice because it's off by one error. So you have to get the first one and then get it, things like that. So we're going to fix all that. Cool. Okay. Splicing?

Speaker 1: 00:16:15

Yeah, I guess on Questions and Splicing, now that Dual Funding has cross-compat interrupt between Eclair and CLN, I guess we should be able to do some splicing interrupt tests as well between Eclair and CLN. And it's going to be easier, and since we will have a Dual Funding PR merge soon-ish, it will make it much easier to rebase the Splice PR on top of the Questions one.

Speaker 3: 00:16:35

So

Speaker 1: 00:16:35

I think it's going to be much easier for reviewers to figure out what is happening and what we are depending on. And it's going to help us clean up that PR and make sure it becomes easier to read and review.

Speaker 2: 00:16:47

Yeah. So one issue with splicing is we decided to go the easy way with Gossip and have this thing where we basically don't consider the channel actually closed until after 12 blocks. So that you get the chance to go, oh, it was a splice, right? So you get continuity. The problem is that channel updates that happened during that time, that first six blocks, new one hasn't been announced yet. The old one is closed, but it's still in that pending state. I know Claire got upset with us sending stuff about dead channels, but we're kind of in a rock and a hard place here, right? You've just done a splice. Can you, yeah, should we have some flag to say, hey, there's a splice in progress or something? I don't quite know how we want to square that circle. Because the problem is a brand new peer starting up who doesn't, you know, has never heard of the old one is going to get upset with you spamming them about, you know, We've already suppressed it so we won't re-announce that old one. The dead-looking channel, just because we won't piss peers off about that. Which is probably, you know, so it's kind of corner case there. So then we'll send them... So we won't tell you the channel exists, but we will send you channel updates about it. And you'll go, that's weird, because that's not any channel I heard about, and it doesn't seem to be in the UTXO set. So yeah, we just, something we probably need to think about.

Speaker 3: 00:18:16

So the issue is that like, splice unconfirmed, six blocks haven't passed yet, and you can't send channel update to the network or your direct peer?

Speaker 2: 00:18:24

Well, we do send channel updates out, but it looks weird to people because you're sending channel updates about a channel that's not in the UTXO set anymore. Right? Now, if they saw I die, right? And they can market somehow is going, Oh, yeah, cool. I understand. This is kind of a zombie channel, I guess, because you're sending channel updates, I assume it's your, you must be splicing or something. But if they never saw the original, then they're fresh on the network. It's kind of weird for you to send them these things about a channel that they can't find. So we did restrict what we were doing there

Speaker 0: 00:19:03

because I know Claire is getting upset with us spamming them about dead stuff.

Speaker 2: 00:19:09

I mean, there's no way, at the moment, there's no way of knowing the difference either. If you've just closed the channel and you haven't spliced, you can still send channel updates. We will go, okay, we'll just keep updating it. I mean, you should be nice and send one out saying disabled. In fact, that's what we will do. If we've actually shut it down, we'll send a disabled update. So That should be all you see. But yeah, it's just sort of a bit vague in the spec. And I wonder if it's going to be a problem in reality.

Speaker 3: 00:19:39

But I mean, did you say that you also have a disable update during the splice? Rusty, or is that just saying for a co-op

Speaker 2: 00:19:44

close? No, for a video co-op close or a unilateral close or anything else, we will send out an update saying the channel is disabled. Yeah. Cause you know, that'll hit you faster than, like as soon as we start, as soon as we enter that state, we send it out. So even for it gets mined, you'll see that. So in our case, you can tell, but we haven't kind of spelled it out anywhere that you should do that. So yeah, as this spreads on the network, I think we will hit more of these issues. People seem to gossip stuff because of it. So

Speaker 1: 00:20:18

yeah, on the other side, we haven't worked really on the gossip part at all yet, but we have relaxed a bit our, when we were screaming at you for sending channel dates that we couldn't see, we had a very low threshold for that, so we relaxed that one and made it, and I think made it configurable as well. So we should not scream at you that much, but that's definitely something that we need to do and we just haven't spent time on the GoSeed part yet. Yeah.

Speaker 3: 00:20:43

Cool. Yeah, I mean, and also people wanna entertain it. They're still the idea of like basically like having this nice splicing transaction, which maybe already is be somewhat identifiable, basically. So then once you hit the chain, you know that it's probably a splice. And you can reuse the anchor or something like that. So that's like, you know, we have that in our back pocket. If whatever reason blocks and you know, p2p stuff, networking stuff, like, it's just not like, you know, it's not tightly synchronized enough.

Speaker 2: 00:21:07

Yeah, Yeah, that's right. I mean, we don't have anything at the moment. One way is to have an option in the channel update to say, hey, this is actually a splice. And you just keep setting that until, I mean, that's cheap, right? We just use a bit. But yeah, we haven't done it and we should see.

Speaker 3: 00:21:25

Yeah, and if the same multi-sig key is used again, then that's also like a, or maybe not, okay. I think

Speaker 1: 00:21:32

That's not the case. At least on our side, that's not the case. We do rotate the funding key for every splice.

Speaker 3: 00:21:38

Gotcha. I see. Yeah. And I guess like the splices have RBF, but if you did add the anchor outputs on that, that would make it somewhat inviolable basically. But then you have extra baggage. Is it worth it just for this one hour period of time or something? Yeah, open question.

Speaker 2: 00:21:55

Yeah.

Speaker 3: 00:21:57

Cool. Then as far as Christians, I'm still not saying that right. We started implementation on our end, at least for kind of like the mechanics, which also takes a very long-standing bug with the way we just like reject clock close if things aren't ready. So at least we're kind of like, you know, figuring out like what that looks like code path wise and L and D side, which eventually go over to splicing and the down quotes and stuff. And then Keegan's recently been looking at the version of down quotes we're working on again. I don't know if you have any updates on that either, Keegan. I saw you open a PR.

Speaker 5: 00:22:26

Yeah, I just put in a draft PR into the main bolts repo that replaces the original dynamic commitments one. It's got a... It is probably gonna tweak a little bit as we finish implementation in LND, but it's close to... It's reviewable at the moment and there are specific line items in the bolt to as notes for reviewers because there are still certain things that might require discussion but it's like a very readable proposal as is I make no claims it's perfect but as far as I know there's

Speaker 3: 00:23:04

no there's

Speaker 1: 00:23:11

nothing wrong with it Do you have a quick primer on how exactly it works and what it builds on?

Speaker 5: 00:23:16

Yeah, so this is something that I wanted to talk about maybe with like the quiescent stuff a little bit, which is that we have an extra requirement right now in dynamic commitments that requires the not only HTLCs to be like doubly synchronized on both sides of the channel so that both sides have fully revoked and committed all of the updates. That's the requirement for Quest and Saziz. But we have an additional requirement that we actually need there to be no HTLCs on the channel. And so we actually do this thing where we negotiate with the dynamic commitment target is, and then flush all the HTLCs before actually applying that. And I tried to make this, when I built this originally, I tried to make it build off of quiescence directly. But quiescence only is just like, OK, things are committed. Freeze things as is. And the trouble with that is that some of the goals of dynamic commitments are to change the channel parameters, which might yield invalid states, or it might result in the fact that the commitment transaction that is current is invalid according to the newly negotiated channel parameters. And while you could work around that by saying like, okay, all future updates must converge towards the allowable space, it's like gonna dramatically blow up implementation complexity. I don't think anyone here wants to deal with that. So, yeah, so I don't know. It is kind of on my list of things to do to see if we can make small tweaks to quiescence or add like a provision that could kind of unify them. But at the moment, it does not actually use the quiescence protocol as it's because of that extra requirement of zero HTLCs, which is overly stringent, but it's overly stringent to protect the implementation complexity.

Speaker 1: 00:25:15

Yeah. The risk is how this step happens. You never get to a state where you have zero HLC or it takes such a long time that you just lose too much on feed revenue, right?

Speaker 3: 00:25:23

Well, isn't this the case with shutdown already, right? That like stuff could just...

Speaker 1: 00:25:27

With shutdown, you are shutting it down. It's not exactly the same. Here you are trying to create a channel, but you still want to use it, and you want to use it as soon as possible.

Speaker 3: 00:25:35

Yeah. That's it. Yeah, you're right.

Speaker 2: 00:25:37

Well, I think it makes sense to have both. I mean, I'll take a look and see if we can do a flag and try to figure out what the semantics are. I mean, if you need to, I agree. There are some changes you do not want to make to live HTLCs. If you want to really be able to mess with some of the channel parameters. I didn't even want to try to get my head around the case of, oh, well, that's not allowed because of this. The things that we've done so far with Questions have all been, have not affected HTLCs. So we've been good and we haven't tried to change parameters dramatically. The only thing is splicing, which is much more sophisticated anyway, has the newer old rule for HTLCs, but that's okay. If you're doing something like, I don't know.

Speaker 5: 00:26:23

Yeah, the things that actually affected are like raising the dust limit would prune a whole bunch of HTLCs off of the commitment transaction. Changing the reserve requirement, right? Might yield an invalid state. Now we already kind of have provisions for that. Yeah. Yeah. Where, like, obviously, if you're at a channel open or the receiver of that channel open is under their reserve limit for the initial states, but that's OK. So there are things that we can change that essentially yield invalid commitment states and we can't necessarily predict them. So...

Speaker 6: 00:27:02

Is there a way that you could pre-negotiate? If that makes sense? Like, so figure out, I don't know, maybe that's more complicated. Okay, maybe not.

Speaker 5: 00:27:11

Well, the thing is, the way the proposal is structured right now is that all negotiation happens before the actual channel becomes unusable. So it's like if you can't come to an agreement, your channel can continue to operate as normal all through this. As soon as both sides have essentially axed the thing, it now kind of enters this flushing state where similar to shutdown where you can only take HTLCs off the commitment via fails or fulfills until it hits zero and then all the new constraint updates are applied and then if there's a re-anchoring step then the re-anchoring step is applied at that point too.

Speaker 1: 00:27:47

But couldn't you just, once you reach quiescence, revoke the current state so that you don't have to deal with that invalid state and just when you sign the new one you also sign it at the new commitment index so that you revoke the current quiescent one so you don't have to deal with that state becoming invalid. Because you still have to deal with revoked states that will be invalid after the change anyway. So if you just revoke that one instantly.

Speaker 5: 00:28:14

It's not about the revocation. It's that, well, okay, if you're suggesting, so let's say that you raise the reserve requirement and now the, your channel peer is no longer above it. Now, in theory, you would just reject this at the beginning if it started that way. But if following all of the HTLC stuff, it changed. Actually, this is still a problem, even in the current proposal, I think.

Speaker 3: 00:28:47

But yeah, I think the main thing here is it seems like we need...

Speaker 0: 00:28:48

I'll have to think about that.

Speaker 3: 00:28:49

Yeah, it seems like we need a bit of something, of some sort in the STFU message that says like this is turbo STFU, like everything is fully clear. And the main thing is just like, you know, we could try to enumerate and make sure every single transition actually was able to map the HTLCs, it was easier just to not do that in the beginning. And I guess figure out the cases where the channel is just too high volume. Maybe you can reconnect or something like that. I'm not sure.

Speaker 1: 00:29:12

But would this become much simpler if we did option simplified commitments? Because then it would be if you use an option simplified commitments and STFU then instantly at the beginning you know what is already committed and that user just need to sign back and forth so at the beginning you can say oh we're going to have an invalid state so I'm aborting right now.

Speaker 2: 00:29:33

Yes, that's always true, though. Yes. Self-desimplified commitments make things simpler. But that's also a bigger change, right? You know? So I think if you're All right,

Speaker 5: 00:29:45

what I'm hearing is that there are possibly ways to do this without flushing HTLCs to zero. Bastion, I think that's what you're suggesting, is that there may be opportunities for that. I will go ahead and take a second look and make sure that either that is impossible and come back with an argument for why it's impossible or do the thing.

Speaker 2: 00:30:12

Yeah, let's see how ugly it gets.

Speaker 3: 00:30:14

Yeah, I mean, to my knowledge, like splicing is the same today. Like you don't splice the HTLCs yet, right? Or you do?

Speaker 2: 00:30:21

Yes, we do. We do have HTLCs in flight.

Speaker 3: 00:30:24

Okay, all right, nevermind, I'm wrong. Because I was curious, like, you know, for like high volume routing nodes, like if that is delayed a lot, but if that's not the case, then okay. That's fine.

Speaker 5: 00:30:34

Yeah, it's just like tricky with things like, if you wanted to change the max HTLC value in flight constraint, you're just basically fucked if it's up above that. Now, maybe you just say, all right, well, the negotiation will fail if the resulting, if the result of the negotiation produces an invalid state?

Speaker 2: 00:30:50

I don't think you have to. I think you just clarify it so that those constraints apply on add. So then it works, right?

Speaker 4: 00:31:01

Yeah,

Speaker 2: 00:31:01

sure, you've got one that was weird, but that's okay, right? You handled it before, like you can't get upset about it now, right? So I think if it's really clear where the constraints apply, and at the moment they're all defined to happen in add. So if you said add something, and I'm like, no, fuck off. That's fine. But I don't check again, right? I'm not gonna go back and go, oh, but now that's weird, because it's above our max, like, no, no, no, that check happens at ad time. So that one, for example, is actually pretty clean. There may be other states, I mean, the reserve state, as you say, we already hit the case where you can be below the reserve. That's kind of okay. If I agreed to increase it, then great. That's a future commitment. It's not necessarily a commitment today. We already deal with it. I don't think again, I don't think that's a problem. We still have the ratchet problem that I still have to let you do something that puts you below the reserve as long as it's in the right direction. But we already have that kind of logic. We will have to go through it. Look, and obviously not in the meeting and step through all the cases. But I suspect that we end up with, it seems like a hairball, but I think when we actually break it down, I don't think it'll actually be that bad. And it would be great if we don't have to drain HTLCs because it simplifies everything and it does keep everything flowing, right?

Speaker 5: 00:32:18

All right, so how about, so for the next meeting, then I'll grab an appendix and kind of step through some of these cases or like put an appendix in the proposal that it steps through some of these cases and then y'all can look at it if you all if you're just like I hate this then we can talk about the flushing route.

Speaker 0: 00:32:32

And then

Speaker 5: 00:32:32

if you guys are like, ah, this seems all right, then we can proceed that way.

Speaker 1: 00:32:37

Yeah.

Speaker 3: 00:32:38

Yeah. And then one other thing that we tried to like pull in, I remember, I think there was an idea, like I think it was for like the early open channel like negotiation basically. So we try to have like a vector to basically say like which things are rejected and why. Or at least we're kind of looking at either doing a full TLV or something more compact by that, something that we're looking at on the side that maybe can be repurposed elsewhere. Cool. Okay. Cool. Okay. I guess, all right. Next, We covered all that stuff. Tap reach hands. This is my week to do everything. I have some text vectors that I need to finalize basically to get that up. And then I was finding the thing around the application messages. Now it just ended up being part of the final feature bit basically. We'll just have a switch statement in certain places. Don't imagine it to being too invasive. I haven't invented it yet, but it's literally just removing an app drop in certain places and reordering it slightly. It doesn't really change things significantly. It does change the weight estimation slightly, because obviously, you have that one less opcode, and some places two. That's about it. And so as far as bugs, we fixed a bug in 17.1, which is something related to ignoring, basically, the whole channel re-establish versus funding lock thing, as far as when the announcements were sent. So I think I'll probably try to clarify that a little more in the spec, just to make sure other people don't run into that, because that's the first thing that we fix. But other than that, it's been pretty smooth so far. People are using it. So private channels only, so it's not super widespread yet. But I have some. And yeah, it's nice. Corp Close works. And then on the gossip stuff, so Elle was out the past week or so, but she's back now. And I think she'll be diving back into this. I think last time we talked about re-announcing the old channels or not, things like that. I think we were just gonna stick with just doing the new flow and then looking at what the old one looked like to see, oh, that's right, the other thing was like, mapping between timestamp to block height basically, if you wanna do that or not. I think that was the main interaction that we uncovered there as far as like, which one do you do, but block height's better, but time is a little bit fuzzy. But at least I think our plan is just do the new stuff first, and then make sure the retrofit can work, or look at what needs to be changed slightly, because at least we can announce the new one.

Speaker 0: 00:35:00

Nice. I got out of rebase hell, and I think this week is also going to be a little easier. I would just ask that I not be put back into it because I might get feisty. And Yeah, hopefully going to be able to make a ton of progress, but nothing really interesting besides that because it was a lot of fighting.

Speaker 3: 00:35:23

Okay, cool. Okay. Yeah, so we'll be ready. And I guess, I guess we should think about which version we want to target, because the scripts I guess will change slightly but not heavily. I'm assuming do you guys have the current scripts, basically the thing that's in the PR and not in the comments, like the non-Mescript version?

Speaker 0: 00:35:45

Yeah, but it's pretty easy to change, though.

Speaker 3: 00:35:49

Yeah.

Speaker 0: 00:35:50

I don't really care. Just you can tell me if you want me to use the newer version. That's what I'll do.

Speaker 3: 00:35:56

OK, yeah, I'll probably try to at least have some branch up that we can use to do the neural processing based off of. Okay. Okay, sounds good.

Speaker 0: 00:36:04

Thanks.

Speaker 3: 00:36:23

Did that. Two errors, just like Yost is back on the scene. I don't think he's here. But we've been looking at this thing. I think he commented some updates here. Okay, yeah, because I think Thomas, from Async, responded to some things around requirements. He responded and he reopened it and he has a forest push. Okay, so he's back on the scene. Oh, he's here.

Speaker 7: 00:36:51

Can you hear me?

Speaker 3: 00:36:52

Yep, we can hear you.

Speaker 7: 00:36:53

So, I had like, I think I have two comments on this. So on our side, we have an implementation about 3D, not to use attributable errors yet, but at least to ignore them. So we can be in a root that uses attributable errors, even if we won't require attributable errors. So I had two comments. So there is this problem of what do we do if we receive a, like if when we, when we forward the error, the error is actually not forwardable because it's not, it's too small. For instance, it's a legacy error. So I think maybe we should add a new error message in the spec for this case. You said that in his implementation, he uses a different method, which is to just pretend that he received just zeros. That's another possibility. And the other problem is the way we signal that we support attributable errors. No, not, sorry, not that we support it, but that we want to use it. So what use proposes is that we put inside the payload the bits that says, please use attributable errors. But the problem is if the onion is not readable for some reason, should we use the legacy errors? Should we fall back to the legacy errors or use attributable errors by default? So a solution to that would be to put these bits to use the attributable errors, not inside the payload that's encrypted, but in the message when you add the HTLC.

Speaker 3: 00:38:46

Interesting.

Speaker 1: 00:38:47

We would trust everyone to relay it and re-add that flag for the next HTLC and the sender should check that everyone in the path supports it and the intermediate nodes should just relay that flag in the updated HTLC message. Is that correct? Exactly.

Speaker 2: 00:39:02

Yes. But they have to understand it anyway, don't they, in order to relay it backwards correctly?

Speaker 7: 00:39:06

So. And actually, they may not even have to all understand, like even if we can have like the first nodes that understand the attributable errors and then like the suffix of a path that doesn't support it and that could work.

Speaker 2: 00:39:27

But it makes sense to put it outside the... Because you may not know. You set it, you send it to the first one, it won't forward it. If it doesn't understand it, it will just go ignore the TLV.

Speaker 7: 00:39:39

It'll do

Speaker 2: 00:39:39

it for you. Right?

Speaker 7: 00:39:41

You need to make sure that they support it. So why?

Speaker 2: 00:39:46

Oh, you're gonna send them? No. Do you Can't you just set it and if it does, they don't support it, then you'll get back a legacy error?

Speaker 7: 00:39:55

Yeah. Okay. Yeah. Yeah. I guess it's

Speaker 2: 00:39:57

like literally the thing about putting it not in the, in the onion, but putting it alongside it, like in the addHTLC message. You just set it all the time and it doesn't hurt.

Speaker 3: 00:40:07

Yeah, because that's what blindedPath does, right? It kind of has something outside to interpret.

Speaker 7: 00:40:14

Yeah, but I mean, you only need to put it if you received an HTLC that has it. If you forwarded an HTLC and you didn't receive it...

Speaker 2: 00:40:24

Exactly. You wouldn't set it on one that didn't have it. But you will clear it if you don't understand it. That's natural behavior. So I think that's actually kind of nice from an implementation point of view. You'll just set it on everything. And to start with, no one will support it. And it'll just be clear all the time.

Speaker 7: 00:40:45

But. Yeah. So that's it. Apart from that, I think the proposal is quite good as it currently stands. The implementation is almost ready on our side. We just need to clarify these small points and review it.

Speaker 3: 00:41:00

Okay, cool. Yeah, and I can make use to, you know, get some interop testing going as well. I think we're looking at getting some basic versions in 0.18, which would be like our next major. We just did one a few weeks ago. So, yeah.

Speaker 1: 00:41:12

Okay, so you'll have some support in master or in a branch that we can test against?

Speaker 3: 00:41:16

Yes, it's in a branch. It probably needs a rebase, but it's there. And it works at least LND to LND. But I can try to find exactly where that is.

Speaker 1: 00:41:27

Okay, cool.

Speaker 3: 00:41:33

Yeah, there's a branch. Okay. And I can link it in the notes too. Just so. Cool. That's it. I guess now this is everything else.

Speaker 1: 00:41:59

Yeah, I think Lisa had a question about liquidity ads and maybe making it a blip or updating it.

Speaker 3: 00:42:05

So... Yeah, I can weigh in. I'm...

Speaker 6: 00:42:10

So now that dual funding is like almost over the line, which is very exciting, I'm kind of turned my focus back to getting the dual liquidity ad spec updated and kind of like rebased on top of the existing the funding implementation, like spec stuff. One of the big changes we're gonna make to the current spec is going from, like this is my kind of a minor thing, going from CSVs to CLTVs, which I think works really well. It means kind of a little less work in terms of the protocol messages that are required for that. The other question that I had, and I think Bastian and I were kind of talking about this offline a little bit, is whether the ads is part of the bulk specification, or if we should submit it as a blip. I think both of us are a little agnostic in terms of where it should go. But in terms of it's currently written as a full update, et cetera, and ideally it is a standard that everyone supports on top of full funding such that everyone is able to participate in liquidity market. But I don't know. Bastien thought it was a good idea to turn it over to the wider spec committee just to see if there were strong opinions either way. Is that correct, Bastian? Did I characterize that correctly?

Speaker 1: 00:43:26

Yep, perfect.

Speaker 6: 00:43:28

Cool. Great, okay, Sounds like everyone is about the same where we are with that one. So we'll just continue with how it is and see where we go with that. Cool.

Speaker 2: 00:43:47

Yes. I want to see what it looks like with CLTV. I mean, CSV thing was a cute hack, but for minimal change, but

Speaker 3: 00:43:57

maybe it'll be nice. We do a CLTV thing too. We have a channel type that just basically has the extra delay and we ended up doing the TLTV. It wasn't too bad. We haven't updated it for Tepper channel and stuff yet just because it was just different. But yeah, The only thing is you have a drift before it confirms. So if it takes three days to confirm, that eats into it, and that's the main trade-off there.

Speaker 6: 00:44:21

Yeah, so I thought through this, and I think for the liquidity-add particular case, I think that's totally fine,

Speaker 3: 00:44:29

because the

Speaker 6: 00:44:30

person who's paying for the fees for the transaction is the person who pays for the fees is the one who is getting liquidity. So you would think that they're incentivized to pay an appropriate... If the one who's opening the channel is the one who's going to be receiving the service, if that makes sense, of the additional liquidity, so it's in their favor for that transaction to get confirmed. So if they decide to make it lower, then basically they're eating at their own CLTV, right?

Speaker 3: 00:44:57

Because

Speaker 6: 00:44:57

that block wasn't a benefit for them. So if we don't pay enough to get it confirmed in a timely manner, then they're basically losing out on the CLTB time anyway. I think in this particular use case, it's totally fine. If you guys have a draft of the CLTB that you guys added to the commitment transaction somewhere, might be useful to use that and converge, if that makes sense. So if we do the same thing, if you have some debts somewhere written up, I would love to incorporate it. Cool.

Speaker 3: 00:45:26

Yeah, I can think we have a write up somewhere. And then on the side, I feel like the final thing that's sort of semi on top tier is like the whole fees thing. Because I think Magma does a thing where they'll say you're bad if you change the fees. And I think the only way you could actually do it is to have fee updates to be signed by both parties. Then you could have the other party reject. But other than that, like-

Speaker 6: 00:45:43

So the cool thing I think... So one way that... So I was actually talking about this with Chris, Rita, and a couple other people here last night, I think the way that the spec is written currently, we're basically doing what amounts to a fraud proof. You get a signed signature from the selling party, the person selling you liquidity at the time of creating the transaction. It has their signature on it, and it says that they're committing to keeping their funds, their fee rate within a certain band. And then at any point, if they sign a channel update from their node during that period that the lease is for, you have two pieces that are signed by them that conflict to each other. So we don't have a process right now for adjudicating fraud proofs, but the spec includes them. And it's part of the currently implemented spec that Correlating has, which is pretty cool. Anyways, so like-

Speaker 5: 00:46:36

I was just going to say, it's not hard to set up a service provider to ingest those things and publish them out.

Speaker 6: 00:46:41

Yeah, exactly. But I think the cool thing is we're currently basically building fraud proofs already, so we wouldn't need to change anything about gossip or how channel updates happen because you already you basically get the you basically would get both pieces that you would need to prove to anyone any third party that they violated a contract in science which I think is cool The only thing that I would really want to make sure is, the only thing I would really want to like double-check or confirm is that the block times are in those, so you can verify that like the signatures so to speak, or like the timestamps are like, you know, so like if you have the two pieces you can check that like the gossip update occurred in a time period or the email update occurred in a time period when they said they wouldn't. The only thing I think we'd want to double-check in this fact. But otherwise, I think it's pretty cool to have like properties built in to the spec.

Speaker 3: 00:47:38

Tough.

Speaker 1: 00:47:46

And I was- In that case, for proof is the same thing as another topic we discussed on the mailing list is that if this is a private channel and you're using SCID alias, the only channel updates that you will get are for your alias. So you don't have a mapping from that to the actual on-chain output. So you need the liquidity provider to also sign the channel update that uses the real SCID and not only the SCID alias. Otherwise, you cannot prove the link between that channel update and the actual channel.

Speaker 6: 00:48:17

OK, that's good to know And maybe work for. I think one of the cool things about this fraud proof is maybe we could talk to Magma to ingest it. If you have a problem, you can send them the fraud proof and then we'll incorporate it in there or whatever. I mean, that's a thought. But, yeah. That's all I had on that. I'm excited about it. I think it's a really cool spec and I'm excited to update it so it's a little less burden. The current implementation, I think, takes a little more work than is necessary. And the big GLT people really fix that, which is cool.

Speaker 3: 00:49:01

Cool. Anything else? I just posted my notes. Okay, if that's it, I'll hit stop record.
