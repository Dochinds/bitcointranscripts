---
title: Lightning Specification Meeting
transcript_by: carlaKC via TBTBTC v1.0.0
tags: ['lightning']
date: 2023-04-24
---

Speaker 0: 00:00:02

I

Speaker 1: 00:00:03

guess there's this older issue too that we were about

Speaker 0: 00:00:06

to. Cool. All right, so first thing I've got on deck is 1066, which says, correct final TCL TV handling and blinded paths.

Speaker 2: 00:00:18

Yeah, I haven't dug as deep into the blinded path stuff, so this may be just like an incorrect reading that I was confused to. Basically for a blinded path, we don't have a final CLTV for the recipient because we just have a full CLTV delta for the full blinded valve and so the spec is very clear that you have to include the final CLTV delta for the recipient but that's kind of nonsense because we don't in fact have one. Val claimed that this or Val's read

Speaker 0: 00:00:52

of

Speaker 2: 00:00:54

the Eclair code seemed to be that it does what I described here just always says basically zero plus you know if it added any extra value it'll include that as like you know if you're doing randomization you want to include you have to tell the recipient that you randomized and how much you randomized by so that it checks that, But I think kind of aside from that, there's nothing else to include. So I guess Rusty and T-Best aren't here. And really the two of them need to comment on this, but that basically summarizes it. Yeah,

Speaker 0: 00:01:34

because I guess you're saying that, like, in this case, the receiver makes the last hop anyway, so they know what that value

Speaker 2: 00:01:38

is. They know what the delta should be from basically the current block height,

Speaker 0: 00:01:44

yeah.

Speaker 3: 00:01:49

Yeah, I'm on Will's computer. But another thing to note is that in the route blending spec, currently prior to Matt's PR, there's a max CLTV expiry field that's intended to be in the Bolt 12 invoice, but it's not. So I think that would have solved that, but it seems like from what I read in Eclair's code that they just put the shadow offset.

Speaker 1: 00:02:15

You're

Speaker 0: 00:02:16

saying that there's a new field in the Bolt 12 invoice that was meant to be but like got left out or something? That's

Speaker 3: 00:02:21

what it looked like when I looked at the route planning spec. Like it mentioned a max CLTV expiry that was intended to be in the invoice, but it's definitely not in the Bolt 12 spec. And I think what Eclair's doing makes sense. It's just the spec is not up to date to it, if that makes sense.

Speaker 2: 00:02:39

So should that be a separate PR to remove that field that doesn't actually exist?

Speaker 3: 00:02:47

Yeah, I thought it was in your PR, but yeah, if it's not then... Oh,

Speaker 2: 00:02:50

I forgot to do it. I know you'd mentioned it, I forgot to do it, I'm sorry. I don't know if you want to do that. Yeah,

Speaker 3: 00:02:56

I'm happy

Speaker 0: 00:02:57

to.

Speaker 1: 00:02:59

Gotcha, yeah, I need to catch up a bunch of blinded path stuff in general,

Speaker 0: 00:03:02

so I don't have too many thoughts other than like something something test vectors, but I guess we have to like see exactly what the desired behavior is and what this stuff prescribes right now.

Speaker 2: 00:03:14

Test vectors? Just test it in prod, What are you doing?

Speaker 0: 00:03:18

Oh, I've got some ideas how we can test in prod. Cool. Okay. Um, all right. We're done some basic notes there, I guess. Onwards.

Speaker 2: 00:03:30

Cause I

Speaker 0: 00:03:30

guess we need people that have implemented stuff. I don't know, Carla, does this make sense to you? I don't know if you got the bar. It seems

Speaker 4: 00:03:36

to me what I've done was so low level that the API just requires that you give it a final CLTB because we just did a pathfinding in L&D. But if you were to couple it all together, you'd need

Speaker 0: 00:03:48

it. Cool. All right, I just noticed mark that to people to look at. I guess I'll tag you to ask me on it too. Cool. Um, next thing on here is just like, the list we've had for a while. Any messages? I think Last time something, some test vector regenerate. Looks like we have some new comments from Thomas H. I think. Looks like it's about test vector stuff.

Speaker 2: 00:04:27

Yeah. Sounds like just probably needs to, looks like they referenced an update in their code and then unclear. I

Speaker 0: 00:04:37

guess. Yeah, and I think it was also rebasing this after the bypass was actually merged into, so. That's done and then now it's test vector, so. Okay. Okay. Cool. I think offloading a similar test vector state. Okay, this has also been rebased.

Speaker 1: 00:05:15

On top of the rebase item message

Speaker 0: 00:05:17

one.

Speaker 1: 00:05:20

But I guess I don't see any other comments other than rebase stuff. Thank you for supporting the implementation.

Speaker 2: 00:05:36

Yeah, no further comments there from our end, I think. I mean, I can let Jeff comment. We're still a little bit away from interop testing. We've got all the data structures done. We just have to basically wire it up to Onion Messages and that's it to do interrupt testing at least. But we also have to be able to generate blended paths. We're still a little bit away from that, But we got most of the stuff done.

Speaker 0: 00:06:04

Yeah, it may PR

Speaker 1: 00:06:06

with the integration of funding messages. There's probably a few changes I need to get in from my gosh,

Speaker 0: 00:06:13

good. Cool. Cool. There's this desk thing, which I think last time was just like a call for you to look at, which is 919. I think you guys looked at it and asked if you would take a look at it. I don't think that's happened since then. Yeah. That was like in February even.

Speaker 2: 00:06:42

Yeah. I haven't had a chance.

Speaker 0: 00:06:45

Yeah. I need like a reload context to be honest too. I think it's like a summarization of what we do today. But wanting to

Speaker 2: 00:06:51

like, summarization, like after you got fixed by everyone. Sadly, I think everyone is currently drowning in new features to add. And so no one is actually working on it. Backlog on this

Speaker 0: 00:07:03

bug. Okay.

Speaker 1: 00:07:10

I'll make an issue on that one, the tracker for it too.

Speaker 0: 00:07:30

OK. Next, temporary channels. I was going to have this rebase, but I didn't get to my homework. But something I need to do. I think the only lingering thing here was some stuff around the anchor output. Anchor output, basically trade-offs allowing third parties to

Speaker 2: 00:07:57

sweep. The

Speaker 0: 00:07:59

main thing is that basically the internal key they need to make a control block may not always be revealed the way it is right now.

Speaker 2: 00:08:11

Is that an internal change to make it revealed?

Speaker 0: 00:08:16

It depends on what key we use, right? So in the past, we used the multi-sig key in the actual script, but now that's a mu-sig, so that's not always revealed. And the other thing as well, if we were to reuse that key there, that wouldn't allow the other, basically the broadcasting part to even allow to sweep that themselves. So some people came up with an idea of basically modifying the two local output to basically have the replication path in the script path. Which would help for, I think, only public channels, depending on what you put for the internal key. But basically, the main thing is that we can potentially allow it to always be swept at a cost of increasing the on-chain footprint for the average normal delay sweep. But yeah, but if we do as is right now, there's basically a risk that some outputs are left on chain. And the thing is, like, you know, people seem to be sweeping these pretty regularly. Like we actually have been some issues resulting in only like not, you know, probably like recognizing sweeps and things like that. So like, you know, it shows that like they are being swept. And I don't know how many outputs are actually just sitting there on-chain. We could probably look at the actual value of all of them as well. But that's one thing. It's not a big change. It's just a matter of the anchor output stuff, as far as wanting to be swept. I think it is the case that for public channels if we put additional information or reuse information that's going to be in the channel announcement that can give a third party the ability to sweep it. But that doesn't help for unadvertised channels. So, you know.

Speaker 2: 00:09:47

But I can... The issue is that currently you can spend it with a key path. And in order to make it script, you have to somehow expose the script path if you want to.

Speaker 0: 00:09:59

Well, so the idea is that like the third party needs to get the internal key that's committing to the script path in order to be able to sweep it. And depending on what you select for that internal key, the information might not always be available. So for example, right now, I think we basically do the internal key of the two local output, which needs to be revealed in order to sweep with the delay. So then, so basically it means that only if that is swept, can the anchor be swept itself. But if that isn't swept, then the anchor cannot be swept. And in a scenario with that, maybe some disaster recovery thing or so on, like loser channels and stuff like that can just already be swept. So it can be on the chain longer than we want and potentially no one can sweep it unless they know this value. The value can be communicated elsewhere, but it's not like a super big showstopper. I think it's just kind of like that, like right now it doesn't achieve the exact same thing as the anchor did before, which after 16 blocks without any additional information, someone can sweep it. But now it's basically after 16 blocks and the two local party has swept their output. But that's like the main difference.

Speaker 2: 00:11:04

Yeah, so there's a

Speaker 0: 00:11:05

risk of it.

Speaker 2: 00:11:07

For a public channel, we can use something that's like public. I mean, we could like use the node ID or something.

Speaker 0: 00:11:12

Yeah, exactly. But

Speaker 2: 00:11:13

for a private channel, we have to reveal something. Yeah,

Speaker 0: 00:11:16

that's a good point. Yeah, because if you use a node ID, then the party knows that. I guess that's the first time that

Speaker 2: 00:11:20

we're using that for an on-chain output. No, I'm not necessarily suggesting we would, but you could freeze it, add a public key to your node announcement or something and just say, this is my anchor public key, try this.

Speaker 0: 00:11:32

Yeah, yeah. All right, that our part can be, after 16 blocks, now it can be, After 16 blocks and the local party. Yeah, that was one thing And then the other thing that was like a lingering thread from before, just like, you know, refreshing people's context was basically some implications around like which key, which key is used for the, I think it's two remote parties, internal key output. And the idea there is like, you know, right now we have that CSV one thing where, you know, they always need to wait for that one block because of something, something, you know, mempool stuff. And, you know, prior, initially I had a nums then I made it a multi-key because we don't necessarily need that. Then people realize that like, you know, the nums is nice there because it basically allows for people scanning the chain for that output, given that it's a static key. And I think there were some people like, oh, we hadn't used that before, but like, you know, I made something and we can have people look at that something and reproduce it. Reproducing is pretty simple. Like, you know, you take like a hash of like a word, like, you know, lightning tap or something like that, you know, check that point and then concat. If that's not an actual point, you basically concat and injure and increment that. So, But I think it's just a matter of getting people to look at that. If people think it's trustworthy, then that can be used. And I generated one before, but we can use that one or just do something with scratch.

Speaker 2: 00:12:56

That seems fine. Is there some more standard? I guess that's kind of the standard approach to generating a nums point anyway, but I guess. Yeah, exactly. Yeah, so nums point that's used for other stuff, we can reuse that as well.

Speaker 0: 00:13:08

Yep, I think that was the other thing. I'm not sure if other stuff, maybe something, oh, maybe Liquid has one for like their Peterson commitment or something like that. But yeah, it's either try to use another one or just like, you know, run this thing. And there's a pretty set algorithms called like, you know, try and increment basically just a matter of like picking what to reuse or do new one.

Speaker 2: 00:13:32

On the previous topic, since no one else has a, I personally, it seems nice to, to, if we have to increase the on chain footprint, that's okay to reduce the UTXO set size. And this is the like the inefficient outcome anyway. So like a few things, you know, a, it's obvious, it's a lightning channel, so we don't need to like, try to hide it by doing the key path spend, it's just more efficient. And wasting a little bit of space in far like witness or in a transaction size versus reducing the UTXO set seems like a worthy trade off in a case that's already stupendously inefficient.

Speaker 0: 00:14:17

Yeah, and it's not that much additional data. I think it's just like 32 bytes for the sibling hash in the tree, so it's not crazy.

Speaker 2: 00:14:26

Right, so at least my vote insofar as I am even paying enough attention to this to have an informed opinion would be to take the hit, put some extra data there and make it claimable.

Speaker 0: 00:14:42

Yeah, and it may even, I wonder if it's already smaller than the old one also, maybe not, but I'd have to look at it. Maybe it's slightly larger.

Speaker 2: 00:14:52

I imagine it is, but I'm not

Speaker 0: 00:14:53

sure. Yeah, and I guess that's just the one thing. Yeah, it makes revocations a bit more, but like, that doesn't really happen that often. And the you know it's maybe like 65 by traditional or something like that not too crazy.

Speaker 1: 00:15:14

Okay cool

Speaker 0: 00:15:15

all right but I'm actually going to have that rebase and stuff and then I just need to rebase all my PRs on the L&D side. Cause we're doing like a different approach for branches because it's like a lot of changes back on each other. Touches like literally everything.

Speaker 2: 00:15:30

Cool,

Speaker 0: 00:15:30

all right, Check. Gossip stuff. I went through and made some comments before this. I caught up with a little bit as well as far as going through some of the other stuff. I think the biggest thing, I guess there's a few things. One is kind of like, one thing I realized, kind of implications of block height based rate limiting, basically, which is just the stuff around saving up the budget, is that OK? Other things related to channel update errors and things like that. I guess I didn't realize that it would have some of those implications. And I guess also gossip query stuff too. Because I know, I think pretty sure Clare implements the timestamp based gossip stuff because they wanted to sync channel updates more frequently. So now this potentially has some downstream stuff there. I need to reread the section around like the burst, like the burst save up and things like that. And if like, that should be climbed a little more, but I think it's pretty cool that we can get like a global kind of limiting from that. Whereas right now, like

Speaker 2: 00:16:34

even the password, there's just a- Yeah, the most common is just a sender side thing. Shouldn't be too hard to implement. You just always announce a few blocks back.

Speaker 0: 00:16:43

Yeah, and I guess you can just save up. And It's not too hard to know when your last one was in the current height as well, see so.

Speaker 2: 00:16:49

Right, you'll have to store the previous one you used, but that's fine. Yeah,

Speaker 1: 00:16:54

you're right, you should have that. Reverse, I don't know if there's some other thing there. I mean, I

Speaker 2: 00:17:00

think the other big conversation about all this stuff is like how exactly the proof format works and what we want to prove versus what we don't want to prove and over commit versus multi-sig versus whatever.

Speaker 0: 00:17:13

And then there's another thing around kind of like TLV everywhere or not. And I thought funding V2 and splicing used TLV everywhere, but I checked, maybe I checked the wrong place, but I guess it didn't, I thought it did. They don't, at least the implementation PR with Rust does not. Yeah, And maybe it'd be good to have a stance generally on this, going forward for new messages as well, or what parts should be hard-coded. I think the rest of you talked about channel ID, because that's always going to be everywhere, at least in certain messages. I think he brought some points around signaling for compulsory fields or not, stuff like that. One nice thing I just looked at is, for example, like node announcement, I think we talked about removing color and some other stuff in the past. People use alias, not necessarily color. If it was a TLV, that means it's optional, which is nice. People can set it. I don't know what the actual use is, but that's one thing.

Speaker 2: 00:18:08

Yeah, I don't know. Personally, I don't care too much about the coin for all I care.

Speaker 0: 00:18:14

Yeah, But yeah, I think the main thing is for... If we

Speaker 2: 00:18:16

intend to maybe remove, it should be a TLV, stuff we have no intent to ever remove. And clearly, shouldn't remove, it probably shouldn't be a TLV. But I

Speaker 0: 00:18:26

don't really care that much. Yeah, and one thing about the TLV thing is, like, for example, like, you know, I feel like there's two points at which we're talking about for this output thing. I, you know, I said I was gonna make a post last time, I haven't done that yet, but I'm working on it. Two things, one is basically how much the output script should be bound, and the other one is basically, relates to that, how much the value should be bound. By bound I mean it's a channel, and it's one BTC or whatever else, right? But as far as the output scripting, if we make revealing more information optional, that can naturally be a TLV. But I guess the question there is that like, you know, who's going to do it versus not? Is everyone going to require it? You just like sort of like mess up certain goals as far as the end of the reset because you know in that case like it would basically be showing the two Bitcoin keys and then you can say if there's a nil tweak that means you're doing the 36 but then if not then that means you know you're doing something else where it's like you know fancy or something like that. So that's at least one place where a TLV could be useful. I

Speaker 2: 00:19:21

mean, it seems like something where like either most nodes are going to verify it, in which case you absolutely have to include it, or the vast, vast majority of nodes are not, in which case you will just never include it.

Speaker 0: 00:19:35

And

Speaker 2: 00:19:35

it might as well be a new message at that point. It doesn't really, I mean, it doesn't have to be a new message, but anyway.

Speaker 0: 00:19:42

Yeah. Yeah. And I was just trying to at least like write up some summary thoughts on like, you know trade-offs of the looser writing Versus what we have today and like pathfinding and things like

Speaker 2: 00:19:54

that But you intended to put that on the mailing list, right? That seems

Speaker 0: 00:19:58

like yeah, I just I just haven't done that But I'm gonna do

Speaker 2: 00:20:01

it haven't even checked the mailing list. So had you done it, I wouldn't have noticed.

Speaker 0: 00:20:06

Okay, cool, cool. But yeah, just trying to at least move some things out of like comments, cause they can get like lost. Yeah. And it's like, everyone hops on the feed or something. The comments are getting long there. I

Speaker 2: 00:20:16

mean, I'm sure the mailing

Speaker 0: 00:20:17

list is going to be equally unreadable. Yeah, that's what my rule is like. If I'm not part of the thread, there's more than six messages I'm never reading. But if I'm part of it, then I feel like I have to, or if I started it, then I have an obligation, obviously. But even that maybe though. Cool. I don't know if anyone else has anything else as far as the Typer Gotham stuff. I think we're gonna start at least looking at code in like, on the internal things that you need to do, new output type, things like that itself. At least the fields should be the same, even if it's TLB versus not encoding wise, just

Speaker 2: 00:20:54

to get some more familiarity with that. And then we have a towers thing. The big, if we do material over commitment, Rusty was moderately to strongly of the opinion that the proof should be in the channel the note announced.

Speaker 0: 00:21:08

Here we go back to 2.0. The backslide.

Speaker 2: 00:21:11

No over commitment. I mean My point was you could do overcommit without doing that, but Rusty's view is that it should just move and do it cleanly. But yeah, I mean, that's gonna impact, that discussion is gonna

Speaker 0: 00:21:26

impact the code structure point

Speaker 2: 00:21:29

a bit.

Speaker 0: 00:21:30

Yeah, yeah, and just, that'll also further impact just the protocol flow as well, like no down first and then that.

Speaker 2: 00:21:36

So that's going to impact the code structure. I mean, it's not going to materially complexify the code. It's just going to change the structure of it a good bit. Yeah,

Speaker 0: 00:21:44

like This one at least follows the current flow. That would be something very different. But right, okay, I'm always trying to touch.

Speaker 2: 00:21:53

It won't materially change the total, like it'll change the diff a bit, and it'll add a little bit more complexity, but not a material amount. But it will mean the diff compared to the current state of the PR to that state of the PR would be drastically different. So I think we're probably not gonna bother trying to touch code until that conversation is at least marginally resolved.

Speaker 0: 00:22:17

Okay, And then at least I can make that post and just put it out there sooner than later as well. At

Speaker 1: 00:22:23

least start a forum for it. Cool.

Speaker 0: 00:22:30

I mean, we have more stuff to post in my comments, but I can talk through the rest of it and everything. Dual funding. I know there's some stuff around splicing and the messages. There's a mailing list throughout on that, but I didn't really get to.

Speaker 2: 00:22:48

Yeah.

Speaker 0: 00:22:49

Oh, the last thing was the witness stack thing. And that went one way. Looks like some messages emerged or PR versions of Lisa's. Yeah, I

Speaker 2: 00:23:00

think it ended up using the Bitcoin witness utilization format. I also didn't follow it too closely. I don't know if Duncan's here, but Duncan left a comment saying it did. Okay. And then there's this ongoing discussion around more protocols.

Speaker 0: 00:23:19

Should you send multiple messages?

Speaker 2: 00:23:21

Okay. Yeah. Yeah, I'm just signing those. Anyway.

Speaker 0: 00:23:25

Yeah, and I know there's some slicing stuff on the mailing list around like, education is ordering or something like that, but I'm not sure if it's even that. It looks like there's been some comments in the past month or so on the PR. Cool. Uh, I don't think Yost is here, but, uh, next one is, you know, trivial errors, 10, 44, One thing I was thinking about this is that like, does this have implications with blinded paths? Right? Because it changes the error message. I think there's more like HMAC to stuff on it. Can it still be verified if part of the path is like, in the tunnel?

Speaker 2: 00:24:02

I assume I mean, like blind, a blinded introduction point will basically say like, I got back an error that was in the tunnel. Mm-hmm. Leave me alone. So I assume you could, you could at least, you can always verify it, or I assume you could build it, and it, I guess, should be built such that you can verify that it came from the blinded introduction point but then to your point I mean the question then is like well what have you what did you gain you've now learned that it's in the tunnel I guess you know that you have a different tunnel

Speaker 0: 00:24:32

um yeah yeah I think I it feels like the the answer is maybe there's no implications, but at least something that, you know, I think we wanted to look into before we like we had some of the PRs and stuff like that. That makes

Speaker 2: 00:24:47

sense.

Speaker 4: 00:24:48

I've looked at both of these, working on blind and blind. Okay. I've looked at Yost's thing. Given that route blinding pretty much just drops whatever it got up until the introduction point, and then the introduction point returns, and there shouldn't be a problem, there may just be some send-aside thing where you need to make sure you don't overly blame the introduction point because in a normal case, if something dropped all the HMACs, you blame them for being malicious. But in the blinded case, this is what this person is supposed to do. But that's a general blinded paths thing anyway. You need to penalize the whole blinded route, not just the introduction node. Otherwise, you'll hammer them. Right.

Speaker 0: 00:25:41

Yeah. Interesting. Yeah, I'd say put it with my head to actually think about it. It.

Speaker 1: 00:25:47

But yeah, maybe

Speaker 0: 00:25:48

not. Okay. I'm gonna talk about that. Channel reestablish requirements. This is homework that I, IOT boss still for a long time now. Just basically tighten up the spec around reestablish, which is like one of the more involved parts of it. Cool. Peer source backup.

Speaker 1: 00:26:31

This is 881.

Speaker 2: 00:26:36

Oh yeah,

Speaker 0: 00:26:36

well because yeah, Eclair had something a while ago, and I think Sea Lightning rolled something, or Core Lightning rolled something. And maybe this is about, like, reconciling them? I'm not really sure. I'm not, I, cause I think, I think the clear thing is, is live. I think they do it

Speaker 2: 00:26:52

for all their wallets, things like that. I think correlating is live too. I'm not sure whether they're the same or not, but yeah.

Speaker 0: 00:26:59

Yeah. So we had a summer of, summer of Bitcoin intern worked on an experimental feature, and it's live now, but you've gotta manually enable it. Gotcha, okay. So He was, I think, looking for funding to do kind of a follow on, like integrating that into the spec and kind of merging those two. I'm not sure what the status of that is though. Mm-hm.

Speaker 2: 00:27:33

Okay, well, yeah, I mean, anyway, we'll probably do whatever it's spec an option here. I don't know if we'll use it, at least in the short term. We'll probably use it some, but certainly we'll implement it because storing 64K for your peer just sounds like a nice thing to

Speaker 0: 00:27:49

do. Cool. So

Speaker 2: 00:27:57

that's

Speaker 0: 00:27:57

the... All right, that's everything. And then going back down to stale So one thing we're looking at again was the inbound fee stuff And then I guess Matt was saying that like people commented that they wanted to look at other stuff or something But I didn't fully understand that context because I don't think I was at that same meeting. No,

Speaker 2: 00:28:17

I thought you were. I mean, it just, we'd

Speaker 0: 00:28:20

had a

Speaker 2: 00:28:20

previous meeting. I mean, this was months ago. And I think there was a lack of agreement. And then

Speaker 0: 00:28:29

there

Speaker 2: 00:28:29

was some, like, basically, we spent a bunch of time on it and then concluded like, eh, we'll talk about this again because we're not close to actually merging it. And so I just was highlighting that like, if people are getting close to actually moving forward there, we should have that conversation again. Sadly, we're missing a ton of people here, so it's a little hard to have this

Speaker 0: 00:28:53

week. Okay, yeah, I mean, I still stand by my old kind of, you know, perception that like, I think the other one, you can't really rely on someone to broadcast an update for you. And in the future, if there's more at a global level, that's not as compatible basically. You know, one has different, you know, they have different trials as far as deployment, but like the, you know, and also like implications as far as like their own fee schedule and everything like that. The other one indirectly has the similar effect, but like one's directly send a receiver, the other one's, you know, direct peers, which needs to update as well. I

Speaker 2: 00:29:30

think, right, I mean, I think the, you

Speaker 0: 00:29:34

know,

Speaker 2: 00:29:35

you can still if you have, if you hold the position that the only negative fees are going to be adopted, which I don't necessarily agree with, I think it's, in fact, very limiting to what people want to use this protocol for, then you can still do negative fees on both, right? You have the same kind of update policies around it. If your peer tells you, hey, I'm going to assign a negative fee to our channel, like, you have a very strong incentive to go ahead and announce that because, well, it means your channel is going to get used more and your peers the one paying for it. So what do you

Speaker 0: 00:30:10

care?

Speaker 2: 00:30:13

So I don't think that's true. From like, general point of view, It's only true if you're like, it's like an Apple Store and just comparison basically, because the other, the version that is just two peers also supports positive fees, which is an additional further feature that I also think is really important for people actually adopting this. Because just supporting

Speaker 0: 00:30:36

negative fees is very restrictive. I don't see why the other one can't do positive

Speaker 2: 00:30:38

fees. I don't see

Speaker 0: 00:30:39

why the other one can't do positive fees. I think right now it's a sign integer, but we talked

Speaker 2: 00:30:42

about changing that.

Speaker 0: 00:30:43

But you can emulate it. Every node

Speaker 2: 00:30:44

will... No, every node will just ignore it. Like if you announce, hey, I'm trading

Speaker 0: 00:30:50

positive fees.

Speaker 2: 00:30:51

But it's a sender level thing. Nodes will just ignore it. Yeah, and some nodes will ignore it because you have an option to pay more in fees or not pay more in fees, and you will simply not pay more in fees.

Speaker 0: 00:31:02

Well, you can increase your other fees, so then they can pay that or not pay that. And not paying that means not routing, right? Or not getting racial see-through.

Speaker 2: 00:31:11

No, no, because it's not broadly adopted, right? Like you could wait, you could, if we were talking about like every node supporting it and not talking about like some something that is just built for L&D, then you could actually enforce it over time, you know, say like in three years or something. But you couldn't enforce it immediately because most nodes, I mean, certainly today no nodes support it, right? So you

Speaker 0: 00:31:36

have to wait a while

Speaker 2: 00:31:37

until senders actually support it before you could enforce

Speaker 0: 00:31:40

it.

Speaker 2: 00:31:43

Yeah,

Speaker 0: 00:31:43

I guess what I meant is like a combination of normal fees And then also this as well. Like, you know, I need to like actually walk through it, but I'm pretty sure you can use it to simulate positive inbound fees as well, just by like doing your updates and then advertising this as well.

Speaker 2: 00:31:55

Oh, well, yeah. So the problem

Speaker 0: 00:31:57

is it's like a simulation.

Speaker 2: 00:32:00

If you if you sign a further positive fee on all of your channels and then the negative fee to offset it on all of your channels, and then take away that negative fee on one channel. That's true, but again, you have the sender upgrade problem, right? Like you're gonna cause senders to never send through you because you're assigning a huge positive fee for senders that don't interpret this new field. So again, like, you know,

Speaker 0: 00:32:22

the previous

Speaker 2: 00:32:23

point, or the previous proposal was phrased as like, this is a thing for people to try out, and we're gonna see how it goes. And see where it goes. And my point is like, it is absolutely incongruous with people just testing this out because senders have to upgrade to support it. And that's gonna take quite a while and senders aren't gonna actually upgrade. So you can't get good data using this feature for how inbound fees actually impact your routing performance because senders have to Because you're gonna hurt your inbound. You're gonna hurt your routing performance materially by trying to do positive inbound fees and not doing positive inbound fees, which strikes the proposal so substantially that it just doesn't really, is not a good test bed.

Speaker 0: 00:33:14

Well, I think to be seen, if it's a good one or not. And we can see that is by trying it out and seeing if people use it or not. And we can very easily track people that are advertising it because it's a new field. And then there can be just reports on the sender side as well.

Speaker 2: 00:33:32

But all right. But it doesn't actually, because senders have to support it and you're gonna blow up your routing. Yeah, yeah, yeah. The

Speaker 0: 00:33:43

senders that do, And like, I mean, yeah, I think you'd leave it to the routing nodes, right? Because everyone's, you know, a lot of nodes are a lot more sophisticated now as far as like tracking their costs. Uh, and hey, so we can give them a knob and see if it helps or not. They can turn it off. It's completely optional.

Speaker 2: 00:33:58

Right. But my point is that it's not, it's not, it's not like if your goal, if you're coming into this, you're saying like, I want to see is inbound fees are a good thing that allows routing nodes to achieve some end goal. This is not the way to test it, right? Because this doesn't actually allow you to test it kind of quote-unquote completely. It only allows you to test it for a subset of senders which is going to be a very very small subset of testers for a while and then grow to a somewhat larger subset of testers but certainly will never grow to like the vast majority of senders, at least not for for some number of years. So it doesn't really allow you to answer the question are inbound fees, do inbound fees allow you to accomplish X or Y goal, it only allows you to answer the question, do inbound fees accomplish X or Y goal, given a very small percentage of the network is sufficient, is upgraded to L&D version X or Y or running L&D version X or Y.

Speaker 0: 00:35:01

I think it's less about percentage of the network. I don't think it allows you to ask that question. Well, I don't agree. I think it's less about percentage of the network and more about, like, you can say the aggregated volume of certain senders, right? For example, if you just know that, like, I don't know, there's some company or something that actually sends through you reliably and this can help you solve. Which

Speaker 2: 00:35:19

I've upgraded, that's

Speaker 0: 00:35:20

true. Yeah, yeah, yeah, sure. I mean, yeah, it's a center side thing. So you're right, it is bottlenecked on that, but that maybe happens more quickly than you know, which is why we can see if it does or not.

Speaker 2: 00:35:34

My point is that it's not about, my point is that it's not really about like, does you know, 50% of senders or whatever, more does it reach a vast majority because you don't really get a represent quote unquote representative sample to answer the question does inbound fees allow you to accomplish goal x unless you have the vast majority of volume by sender uh upgraded to to interpret

Speaker 0: 00:36:01

for your for your node

Speaker 2: 00:36:04

sure yes for your node yeah yeah but for

Speaker 0: 00:36:06

your node and you know some nodes are more specialized than others. Some nodes exist for a singular purpose in the network today. If

Speaker 2: 00:36:14

a node exists for a singular purpose, that's highly specialized. If a node exists for that purpose, it should just use something that's not in the global broadcast network and tell its peers about it. That doesn't really make sense.

Speaker 0: 00:36:34

Well, OK. All right, I guess we'll see if this works or not.

Speaker 2: 00:36:41

I mean, I think you're pushing something that has an impact on every, every node implementation. I think we should have a conversation about that rather than just saying, YOLO.

Speaker 0: 00:36:51

But, uh, it's, it's, it's optional, right? You're, you're saying that centers can do it if they do it

Speaker 2: 00:36:55

or not. It's

Speaker 0: 00:36:56

really not operators can do it. If

Speaker 2: 00:36:58

you're going to emulate, you're saying you're going to emulate positive inbound fees by assigning a different fee to the outbound edge that's really not optional. And

Speaker 0: 00:37:08

it's like that's one way to do

Speaker 2: 00:37:10

it. That's the same as increasing your fees. You're also assigning, you're also changing fees in a way that has an impact on everyone's routing algorithm. Like in order for a node to

Speaker 0: 00:37:22

materially implement

Speaker 2: 00:37:23

Lightning. No, in order for a node to materially implement Lightning, i.e. Give their users competitive fee rates. I

Speaker 0: 00:37:31

think you're assuming we're jumping to the point where everyone's

Speaker 2: 00:37:33

updated. But you already said that's going to take a long time. I'm saying that you are pushing something that node software, irrespective of users updating, node software implementations really are largely forced to update because they want to give their users like a competitive user experience or a good user

Speaker 0: 00:37:55

experience where they're paying, you know, a competitive amount on fees. You're saying you're saying forcing I'm saying it's an incentive, right? They can, they can take it or leave it or not. No one's enforcing. This is no voluntary network.

Speaker 2: 00:38:06

Very. That's a very similar outcome.

Speaker 0: 00:38:10

Yeah, I mean, I think if you analyze through that lens, I'm sure there's a lot of things we could look back at. You know, that you could say that have a similar effect.

Speaker 2: 00:38:22

Yeah, okay, that's probably true. That doesn't mean my point isn't valid.

Speaker 0: 00:38:29

Well, yeah, I think we're just approaching from different angles. Like You're assuming that

Speaker 2: 00:38:35

everyone needs to do

Speaker 0: 00:38:36

this. I just want to better understand your

Speaker 2: 00:38:37

angle. Sorry? I want to better understand your angle, because I'm not really sure I understand your angle here.

Speaker 0: 00:38:41

Well, yeah. I guess what I'm trying to do, I guess my main thing with the other one is that I don't think you can reliably rely on the other node to always broadcast your updates. I think you had some examples that said, okay, well, they're gonna get a certain discount or a fee, but you as a routing node, you don't necessarily know if the sender ever even got that update at all, right? So I think the issue there is that it's indirect. You're telling another person to give a discount in your direction and saying they should do that. This other one is a direct thing. If someone routes through me, I can cancel the HTLC and give them an update directly. And no one needs to know about it. So the other one requires all of your direct peers to update in order to actually push this thing forward and make sure all of your peers are able to do this. This only requires you in the sender. So if only if two people in the entire network were updated, someone could get some value out of this thing versus having

Speaker 2: 00:39:29

all of

Speaker 0: 00:39:29

your routing operators update. And then not to mention potential negative

Speaker 2: 00:39:34

cycle or effects

Speaker 0: 00:39:36

of causing individual to basically always trigger updates. Like if I tell you that you need to do my new update, you know, do you take into that account to basically do your fee schedule and then tell your neighbor and that eventually has a cycle as well. So I think there are different approaches to the problem. And I don't see why you can't put them on in series or

Speaker 2: 00:39:56

concurrently, rather. So let me address your first point. Your first point was that you can't rely, you can't fail on HTLC because you can't rely on your peer to actually send the update. So my point... Oh, I meant that you don't know

Speaker 0: 00:40:11

if the sender has the update because you don't know if the peer is actually going to like take that into account, because they also have their own fee schedule algorithm and they need to take into account this if it's if it's the case for all the other direct peers as well. Right,

Speaker 2: 00:40:24

right. So let me, so I did that was a good feedback originally I did update my proposal

Speaker 0: 00:40:30

to

Speaker 2: 00:40:31

take that into consideration. So first of all, like obviously, your peer can always just decline to forward payments to you so like them explicitly misbehaving and doing something like incorrect is not really a material concern because they can always just do that.

Speaker 0: 00:40:46

Yeah, they may do it inadvertently because they need to factor in their fees and your fees. If that makes sense.

Speaker 2: 00:40:52

Yeah, of course, of course. It's

Speaker 0: 00:40:54

like it's lossy is what I mean. It's lossy.

Speaker 2: 00:40:57

So it's not. So I did update the doc to describe, you know, obviously you already today have to wait some amount of time before you enforce a fee update because it has to propagate. So I did update the doc to take that into consideration And you do obviously see when your peer sends an update message, you don't know necessarily that they received your, your message. But you can, you do know that if you keep track of like, you know, when you sent the message, and when you got the last other message from your peer, It's not super hard. We do that all the time in Lightning. And I did implement that. It's super trivial. And then obviously, of course, you see the next channel update they send after you're sure they heard your message. And at that point, you can be confident that they're actually doing the correct thing at that point, and then you can enforce it based on whatever timeline you already had for HTLC updates. So

Speaker 0: 00:41:59

I

Speaker 2: 00:41:59

don't think that that's now a legitimate concern. I don't know if you read the latest, but the latest.

Speaker 0: 00:42:06

Yeah, I'm not having the greatest one. Yeah, I read

Speaker 2: 00:42:12

the latest one, because that's not I would recommend you read the latest one, because that's no longer an issue. As far as I know, if you find it an issue with it, I would love to hear about it. But that's not an issue anymore. So that just leaves the question of, you know, to your, I guess, your later point was just saying, what is the upgrade procedure like for routing nodes versus their peers versus senders? And then I think that just fundamentally gets back to the question, like, if the goal here, which is at least the stated goal, is to try out inbound fees and see kind of what the net effect is, see whether it achieves certain goals that routing node operators think it will achieve, then the question is which one better achieves, which set of nodes having to upgrade better achieves that goal? Is it just peers of the routing node operators that want to test this feature or is it senders or representative set of the senders routing through that node. And I am fairly confident that it would be just peers. Because, you know, you probably to your point, you know, you probably only have a handful of channels that you want to apply a certain fee rate policy on, certain inbound fees, because you don't want that capacity to get used towards you. And so you really just need to get those specific node operators to update. And presumably, that's a much easier task than a representative sample of senders. You're right that there are definitely some nodes that, you know, are operating in an environment where they only really care about one sender or small group of senders. So in that case it might be easier but even there I would I think like those nodes that are only caring about one or a small group of senders also are only caring about one channel right Like if you're a node that's like sitting right next to loop and you want to charge something based on that, or you're sitting right next to another node that charge something based on, that's really only like, if you're talking about one sender, you're also only talking about one channel that they're using or one set of channels that they're using. And again, I think that's, you know, it's much easier to talk about that one node being your peer updating, because you already also have a relationship with them. Hopefully you can ask them to update. Well,

Speaker 0: 00:44:45

yeah, I mean, I think that makes a lot of sense about like the test bed and the node environment and how quickly your nodes will update and so forth. But I still assert that like, one can be tested with two people updating and the other requires hundreds or even the entire network itself. Now, I think it's a pretty big difference, right?

Speaker 2: 00:45:02

So I don't, can

Speaker 0: 00:45:03

you give me an

Speaker 2: 00:45:05

example where that's true? A

Speaker 0: 00:45:07

sender updating and all of your channels.

Speaker 2: 00:45:09

Well, I mean, But where you only care about one sender, but you also care about many channels.

Speaker 0: 00:45:15

Yeah, yeah. One sender is the reductive case basically, right? That like if you know that there's a wallet app out there, and for whatever reason, this wallet app ends up, you know, sourcing a lot of your traffic because you have some like peer relationship or other things. This lets you do that. The other one requires all the peers to update. We know, we do know that like there's a lot of things people are working on right now, network-wise, right? Will all of them update in time? And you also can't rely on this thing to be enforced reliably unless all of your peers are updating. That seems very fundamental to me. No,

Speaker 2: 00:45:45

that's not my point. That's not my point. I think you missed my point. My point is that if you only care about one sender, then you probably also only care about one channel, right? That if you care about one sender upgrading, then that one sender is probably using your one channel from that sender or, you know, through one specific path, um, from one of your peers. Right. And so again, you're like, you only have one channel you care about. Like if you have one sender you care about, you also only have one channel you care about.

Speaker 0: 00:46:16

And

Speaker 2: 00:46:16

so the upgrade

Speaker 0: 00:46:17

requirements there

Speaker 2: 00:46:17

are the same.

Speaker 0: 00:46:19

I don't know about that. I don't think that's the case. Because like, you know, those peers can use any of your channels. You're saying that if you care about one sender, they're only going to use one channel? But does that mean that you're bound? Does that mean you're bound with that one channel for that one particular peer? I think it's a pretty fundamental difference.

Speaker 2: 00:46:43

No, if you have a, like, I'm saying,

Speaker 0: 00:46:46

yeah, so basically, you're saying restricted to that one peer and one channel and one implementation.

Speaker 2: 00:46:52

No, what? No, So I'm saying if I have, so you're saying, you were arguing that like the, it's easier to update or it's easier to get useful information with the announceability Because

Speaker 0: 00:47:08

we only need to care about because whoever

Speaker 2: 00:47:11

gets the announcement. Particular center,

Speaker 0: 00:47:13

maybe. What is reductive? It's just whoever gets the announcement. It's whoever gets the announcement. Okay,

Speaker 2: 00:47:20

what has updated? We're talking about a number of things that need to update in order for someone to, in order to get useful data from this experiment, right? Yeah,

Speaker 0: 00:47:30

and I'm saying like those two endpoints, that being the one node and potentially, you know, the set of centers.

Speaker 2: 00:47:37

I'm saying that it's actually equivalent. So if I'm a node, I

Speaker 0: 00:47:41

think, I think that's where we fundamentally disagree.

Speaker 2: 00:47:43

One or five. Can we talk it through then? Because I don't understand your point there.

Speaker 0: 00:47:49

Well, but like, so you're saying the number of nodes to update to like have meaningful data or an experiment is the same, right? And I say that's not the case. Imagine one node that has 100 channel peers, right? 100 channels that are reliably used for various purposes, right? All 100 of those need to be updated to allow a sender to take any given path to that node, right? But you're saying If they only take a single path, then only one node needs to update. Yeah, sure, but what if they didn't want to take any

Speaker 2: 00:48:21

of those hundred

Speaker 0: 00:48:21

paths to that node?

Speaker 2: 00:48:23

So, okay, so first of all, we're talking about just the inbound path. And while it's true that a node might take one or two or three different paths to reach a node. It's fairly uncommon, at least when I look at like routing graph or when I like try different routes to a node. It's, you know, fairly uncommon that there's more than just one, two, or three that me and individual sender are gonna take to a given node and that's doubly true if that nodes close to me if that nodes close to me in the graph. Are

Speaker 0: 00:48:56

you even assuming MPP? I think if you assume MPP like that already you know breaks down right? You're probably gonna take multiple paths and even for like real primitives you can take multiple paths.

Speaker 2: 00:49:07

But I'm not so so we're talking about like a node that's close to you, right? Because we're talking about like specific cases where there's only a small subset of nodes of senders that need to update in order to take advantage of this feature. And I think mostly we're talking about routing nodes, not sending to. And so that's for MPP is a little less important there because generally when you're MPPing you're not gonna like Send five MPP parts through the same node via different channels Normally not least in my experience

Speaker 0: 00:49:46

Yeah, okay But I don't know about It feels like you're making a lot of assumptions around like how people run writing nodes, the way senders work, things like that. But I stand by the end to end assertion, right? That the end to like one is end to end, you need two people to update the other, you need several other individuals with direct channels to update. I don't know how you can like, you know, get

Speaker 2: 00:50:09

around that. That

Speaker 0: 00:50:10

seems very fundamental. Like it, we've done this a lot in the past. That's very fundamental. For example, we were able to add the metadata field in the invoices, right? Because that was an end-to-end update. That only required the person giving you the invoice the person is sending to update. This is a similar thing. Only the sender and the internal

Speaker 2: 00:50:28

node that they're routing through. Does anyone enforce metadata? I don't think so, right? Because it's pretty not it's not universally supported, is it? I don't

Speaker 0: 00:50:37

think anyone. Well, I think people people want to move it to for payment secret, but that that seems beside the point. But yeah, it seems like we have a

Speaker 2: 00:50:46

very different

Speaker 0: 00:50:46

view of network updates and who needs to update versus not. I think I've written down my views for what constitutes an end-to-end update. It's

Speaker 2: 00:50:56

not a fundamental question here. This is not some foundational question. This is like a, no, this is not, this is a specific question for a specific experiment. Like if, if our, so like,

Speaker 0: 00:51:07

let's

Speaker 2: 00:51:08

be clear, like if the stated goal is we want inbound fees and lightning, then we should be going about this in a different way. And maybe, maybe what, maybe your design is actually

Speaker 0: 00:51:16

probably better. But the thing is, Matt, like taking that approach in the future does not preclude doing incremental things today, right? That's just how this works, right?

Speaker 2: 00:51:28

Right, I know, so that's not what I'm arguing. I'm just saying that if our goal is to have, get to a point where we have inbound fees, we should be doing inbound fees because every sender has to update to do that and we should just do it, right? If our goal is to experiment for like, can we build something that demonstrates inbound keys are useful and like, you know Let's let's build something and actually try it then we need to talk about like how do we get the best data with the minimal amount of effort And I'm still very confused about kind of your take here that fewer nodes need to update in order to get the best data. Yeah. Because I don't think that's really accurate here.

Speaker 0: 00:52:12

Yeah, I think we just have, I think we're just looking at this very differently. You think

Speaker 2: 00:52:17

everyone is up to date. I'm really trying to understand your view here. Well, yeah, I think... I'm saying in order to get good data, you need basically the vast majority of senders who are sending through your routing node. Not... And

Speaker 0: 00:52:29

I thought you agreed with that. It doesn't necessarily need to be the majority. It can be weighted by volume they give out. And I think the other thing around the channel update is that we would have a very clear signal. Yeah, sure. We would have a clear signal of which nodes are even using this feature in the first place, right? If we do this And none of the LND nodes actually do it at all, and there's only two of them. And they say it's cool. OK, well, they can implement that on a side by having a custom message or something like that, or adding custom data to the TLV. And that could be an RPC on the side. But if we do it, and then we're finding the vast majority of them are actually setting it, then we can say, okay, well, we can go talk to those individuals, we can say how's working for you, you know, is it actually, you know, resulting in better traffic, they can

Speaker 2: 00:53:07

look at a lot of stuff down there. But we can announce that you can announce the data in in both designs, right? I don't think the whether or not you announce the data in the channel update precludes whether or not you do it in like this restricted negative case only or if you do it by like negotiating with your peer and then you also set a TLB bit and just say like, hey, I'm using this feature, come talk to me. I think that's an unrelated question. You can do

Speaker 0: 00:53:38

both. I think it's related because the mechanics of these are very different, right? I think we can at least

Speaker 2: 00:53:42

agree on that. The mechanics are very different. Right, And I want to focus on the mechanics and like the material difference with the mechanics and whether which one is going to get us more useful data easier, quicker. Sure. I mean, yeah, we

Speaker 0: 00:53:58

can look at the mechanics. I think one mechanic is indirect. The other one is very direct. Uh, and in any case, like, you know, this isn't a global level update basically. And people that have different, you know, vantage points of how to best correct, collect the data, they can do so. And we can then see at the end, which one worked or not. And maybe it doesn't do anything. Maybe if you were working on another stuff, uh, it's just like, yeah. Um, both routes are feasible because this is this is a fully optional thing you would say it's not optional and I think that's what we diverge. I think it's what we diverge. Do you think it's optional? You think it's not optional? I think it is.

Speaker 2: 00:54:35

Irrespective of if it's optional, let's ignore that for a moment. I'm just trying to understand which one is going to get us better data with less effort and less nodes that have to update. And I'm very, very unconvinced by your arguments there.

Speaker 0: 00:54:48

Well, but if you're, last thing I'll say on that, if you're saying less nodes to update, go back to that example of a node having 100 channels, which are each equally utilized as far as, you know, doing sourcing inbound or routing. In that case, it's 100 versus 1. So that's just one counter example. If you reject that, you can...

Speaker 2: 00:55:09

But it's not just 1. You're saying it's just one sender has to update. I'm saying 1 minimally. Total volume.

Speaker 0: 00:55:17

Yeah, and maybe there's one predominant sender. Maybe there's one predominant sender.

Speaker 2: 00:55:22

Okay, and my argument is if there's one predominant sender routing through your node, probably they're kind of close to you. And almost certainly, you have one or two channels with peers that are very close, probably the direct neighbor of that node. The

Speaker 0: 00:55:37

sender may be categorized as the same Wallace software, but not necessarily the same individual, basically. Yeah, like last time, to paraphrase, I think Rusty was like, hey, I don't know if this is right or not, try it out and see if it happens. I think T-Bass expressed something similarly. Just try it out. So I think we're just at like, let's just try it out phase. I think Matt's saying maybe another one will give you more pertinent experimental data. I think that depends on a number of caveats and his envisioned scenario and who's not. It just doesn't feel like we need to be in a gridlock to let people launch experiments that can be rolled back very easily just

Speaker 2: 00:56:12

by not setting the field. I'm not suggesting any kind of gridlock. I want to understand what the

Speaker 0: 00:56:18

like... Well, yeah, Matt, you posted on a PR and said, don't do this. You posted on a PR and said, don't do this. Yeah, well... If that's not gridlock, what is? Because

Speaker 2: 00:56:25

I think you are also pushing other people to, you know, you are, well, don't do this and let's have a conversation about it and then you can do it is a very separate question. But, you know, you are also-

Speaker 0: 00:56:34

Well, but yeah, the thing is, it feels like we have a conversation, but we have a very different view of routing. Because the

Speaker 2: 00:56:40

conversation we had concluded with, let's have this conversation again. So that's why I'm trying to have the conversation

Speaker 0: 00:56:45

again. Yeah, I think we're here again. Yeah, I think I think we just have very, very different views on like, how the routing network works, what routers have been asking for over the past few years, you know, the the level of pertinent usage we need to get for experimentation purposes. And to me, the only way to resolve that is just try it out. If we try it and nothing happens, no one uses it, we're not able to get pertinent data and you're able to launch another experiment that's a slightly different way that gives you very, very strong signals, we'll clearly look at you know, what actually happened empirically basically. Right? Sometimes like, you know, just to do is to actually find out, right? Right. With that said, I don't know if anyone has... You

Speaker 2: 00:57:23

have two options in front of you. Sounds like we're out of time.

Speaker 0: 00:57:29

Yeah, I think we're out of time. I don't have any other final, final stuff. One thing that I think we're going to look at, not for this one, but is the WebSockets thing. I think that it sort of got nerfed because we realized we couldn't just do raw without TLS on the browser level. And then we added the DNS stuff. But I think maybe, you know, picking up on the side, but something super, super on the side. It's still, it's still, I think,

Speaker 2: 00:57:57

just because it makes TLS easy, because you just slap engines in front of in front of it, instead of like having to have the full proxy. So I still think to be clear, I was the one who complained about it or kind of pointed this out, but I still think it should be done. It just, oh yeah, it's less important. Yeah,

Speaker 0: 00:58:12

yeah, we need to do the DNS advertisements first and then we can do this. I also wonder, does Mutiny Wallet use this or do they do something else?

Speaker 2: 00:58:19

Like the... I think they have their own custom proxy because they want to talk to all nodes. And so they don't. And plus, yeah, they want to talk to other stuff. So they have their own custom proxy currently, I think.

Speaker 0: 00:58:35

And

Speaker 2: 00:58:35

I think they also actually know maybe they're in,

Speaker 0: 00:58:39

I

Speaker 2: 00:58:39

don't know if they support browser, if they just support Node.js, then obviously Node.js, you can do TCP directly. I'm not 100% sure. I guess I shouldn't speak for them. I've

Speaker 0: 00:58:49

seen a demo and I think it's browser, but something to check out. Yeah,

Speaker 2: 00:58:53

I know they have a demo. I don't. I think the demo uses a proxy, but I'm not sure.

Speaker 0: 00:58:58

Cool. Okay. All right. I posted my notes. I have an

Speaker 2: 00:59:02

unrelated question, if you have another 30 seconds, Lala.

Speaker 0: 00:59:05

Yep, I'm around.

Speaker 2: 00:59:07

You guys announced doing your routing changes. I couldn't find good sources on exactly How it does, but my main question. Like pathfinding? Yeah, your pathfinding scoring changes. Yeah. My big question was what the probability distribution function you're using for a priority channel probability distribution is?

Speaker 0: 00:59:37

Good question. I'd have to check the code again, but I think it's just a uniform one, like the other stuff. The new one is the one that breaks away from a uniform distribution.

Speaker 2: 00:59:51

Right. I was asking about the new one. Oh,

Speaker 0: 00:59:54

the new one.

Speaker 2: 00:59:55

Is it just

Speaker 0: 00:59:57

like an exponential? Yes, so the new one is like, it's like a custom bimodal

Speaker 1: 01:00:01

exponential function. Okay.

Speaker 0: 01:00:04

I can send you, yeah, I can send you like a Wolfram Afro link just to like, so if you want to like see the, where it actually. Yeah,

Speaker 2: 01:00:13

I was just, I was playing with some similar stuff and was curious what you did and couldn't find. I read through several of your posts and none of them actually explained in detail what the exact function was. It just said like, we're using a thing that assumes it's at the edges, which like, okay, yes, that makes sense. It's a good insight, but I didn't know what the actual function was.

Speaker 0: 01:00:32

Yeah, there's something called like Desmos, I think, where it basically lets you like plot it and then even mess around with it. If I hang on for a second, I can probably find like a very direct link.

Speaker 2: 01:00:44

Well, yeah, I mean, if you've got it, if you don't, that's okay too.

Speaker 0: 01:00:50

This is a bit more. And

Speaker 2: 01:00:54

then for your, are you just chopping off the ends based on like what you know about the liquidity or you're using like historical weighting of the, of that function based on historical failure attempts or success and failure attempts?

Speaker 0: 01:01:09

Because

Speaker 2: 01:01:09

I know you just used like historical success and failure and not like liquidity bounds. Yes, so now like the main change for this one is like generally, we didn't

Speaker 0: 01:01:20

use liquidity bounds at all before. It was just a store for success and failure. But now both of them use liquidity bounds. And then this other one, you know, adds kind of like a, you know, it basically like builds in a more kind of like pessimistic view.

Speaker 2: 01:01:35

So it just, it takes the probability distribution function and chops it off at the liquidity bounds and then uses that basically? Is that what it does? Yeah, yeah, yeah, yeah, yeah. Yep, okay, cool, thank you. Okay,

Speaker 0: 01:01:47

I don't know if anyone in the chat that like knows what I'm looking for. I'm looking for his, his like, I think it's called Decimals. It's like a, it's like a graphing, it's a graphing thing. If

Speaker 2: 01:02:02

you happen to know where it's linked from, I can go find it. You don't have to dig for it.

Speaker 0: 01:02:06

Yeah, I thought it was linked in the actual PR. But maybe... Oh, here it is. I did not read the PR.

Speaker 2: 01:02:12

I only read the announcement. All right.

Speaker 0: 01:02:15

I found two things. I don't know if one of them is what I'm looking for, but I think these have a little bit less information. But- Well, that's all right. I'll figure

Speaker 2: 01:02:25

it out. Thank you so much. Yeah.

Speaker 0: 01:02:27

Yeah, and this one has like a slider too. Yeah, interesting. Okay,

Speaker 2: 01:02:31

you guys have much more complicated. Okay, cool, thank you.

Speaker 0: 01:02:35

No problem. Cool, all

Speaker 2: 01:02:38

right. And one last question, was that like determined by like doing probing or was that like more experimentally determined?

Speaker 0: 01:02:46

So I think initially it started with a sort of like, you know, hunch, like looking at like, for example, okay, like, you know, is the uniform really the best, you know, contribution to apply to this. And then I think it was sort of, you know, verified just by looking at some, you know, initial experimental probing basically. And also just kind of like, you know, you can say inferences based on like the lack of like actual liquidity management that many individuals do. And also that most channels are single funded as well. So it was kind of a combo of like, you know, both an assumption and then some basic probing to verify. And then we're looking at what we look at right now. And then I think also it's the case where there's a value that we can modify that controls how imbalanced things are, basically what the modes look like as well.

Speaker 2: 01:03:26

Sure. Cool, thank you. Not

Speaker 0: 01:03:30

a problem. But yeah, I think we'll do more writing on that as well. Because I think that was just initial blog. It was like a section in a blog post of a bigger thing. But I think we want to kind of do something that zooms in a little bit more on what the process looked like. And once our experiments get further, what change that we actually saw. I think you can hear me.

Speaker 2: 01:03:47

Yeah, I can hear you. I'm not sure.

Speaker 0: 01:03:49

Okay, maybe it was just Sabre.

Speaker 2: 01:03:50

But that's that'd be that'd be interesting. I'd be interested to read that. It was a good insight. I think we'll probably do something similar based on it. We have a few more things that we do beyond the just the liquidity bounds. We're also working on on making more, more useful, but we'll probably do something like your modified probability distribution. I'm not sure if we'll use the same one or not.

Speaker 0: 01:04:17

Cool. Yeah. But yeah, I mean, so yeah, I do have that post coming down in like a month or so and we'll have just more like, and there's stuff in the comments obviously, but that's like, you know, not the same. It's like actual bloggers. Cool. Okay. I posted my notes and then yeah, I

Speaker 2: 01:04:33

guess thanks everybody. Thank you. Cool. Peace.
